---
title: SVM
author: hwang
date: 2024-05-27 17:00:00 +0900
categories: [Machine Learning]
tags: [svm]     # TAG names should always be lowercase
math: true
---

## Support Vector Machine
**분류**와 **회귀** 분석에 사용되는 강력한 지도 학습 모델이다.

- 목적: 두 클래스 사이에 **최대 마진**을 가지는 초평면(Hyperplane)을 찾는 것.

> `마진(Margin)`: 클래스 간의 경계로부터 가장 가까운 support vector 까지의 거리{: .prompt-info }

> `초평면(Hyperplane)`: n차원의 데이터 공간을 n-1차원의 초평면으로 나누어 분류한다.{: .prompt-info }

## 선형 SVM 분류

데이터가 선형적으로 구분 가능할 때 사용한다. 초평면을 사용하여 데이터를 분류한다.

### 하드 마진 SVM
![SVM Hard Margin](/assets/img/svm_hard_margin.png)

> `결정 경계`: 검은 실선, 두 클래스 사이를 최대한 분리한다.{: .prompt-info }

> `마진 경계`: 회색 영역, 결정 경계로부터 동일한 거리에 위치한다.{: .prompt-info }

> `서포트 벡터`: 마진 경계에 위치한 빨간색, 혹은 파란색 데이터 포인트이다.{: .prompt-info }

모든 데이터 포인트가 마진 경계 밖에 위치하도록 학습하는 모델이다.

- 이상치(outliner)에 매우 민감함, 이상치에 의해 결정 경계가 왜곡될 수 있음

- 데이터가 **선형적으로 완벽히 구분 가능한** 경우에만 작동

### 소프트 마진 SVM
![SVM Soft Margin](/assets/img/svm_soft_margin.png)

마진 내에 일부 오류를 허용하면서 최대 마진을 찾는 모델이다.

- 데이터가 선형적으로 완벽히 구분 가능하지 않아도 작동

- 이상치와 노이즈에 덜 민감함, 현실적인 데이터 셋에 적합

- **C 하이퍼파라미터** : 마진과 마진 오류 사이의 균형을 조정

    - 'C' 값이 큰 경우: 마진 오류를 줄이는 데에 중점을 둠, 마진이 좁음, 과적합 가능성 증가, 이상치 민감성 증가

    - 'C' 값이 작은 경우: 마진 오류를 더 많이 허용, 넓은 마진, 과적합 가능성 감소, 이상치 민감성 감소

## 비선형 SVM 분류

데이터가 선형적으로 구분되지 않을 경우 사용한다. 커널 트릭(Kernel Trick)을 사용하여 데이터를 고차원 공간으로 변형한다.

### 다항식 커널

다항식 커널 함수는 다음과 같다.

$$K(x, y) = (\gamma \langle x, y \rangle + r)^d$$

> x, y는 입력 벡터이다.{: .prompt-info }

> γ (gamma)는 스케일링 파라미터이다. (일반적으로 γ=1){: .prompt-info }

> r는 상수 항 (bias term)이다.{: .prompt-info }

> d는 다항식의 차수(degree)이다.{: .prompt-info }

- 고차원 매핑: 입력 벡터를 고차원 공간으로 매핑한다.

- **다항 특성**과 같은 특성을 추가한다.

- 낮은 차수의 다항식: 매우 복잡한 데이터셋을 표현하지 못함

- 높은 차수의 다항식: 모델을 느리게 함

### 커널 트릭 (Kernel Trick)

다항식 커널을 사용할 때 데이터를 실제로는 고차원으로 변환하지 않고, 점곱의 결과를 다항식의 결과로 변환하여 계산량을 줄이는 방법

### 가우시안 RBF 커널

가우시안 RBF 커널 함수는 다음과 같다.

$$K(x, y) = \exp(-\gamma \|x - y\|^2)$$

> x, y는 입력 벡터이다.{: .prompt-info }

> γ (gamma)는 커널 함수의 하이퍼파라미터이다. (일반적으로 γ>0){: .prompt-info }

> ∥x−y∥는 두 벡터 x, y사이의 유클리드 거리이다.{: .prompt-info }